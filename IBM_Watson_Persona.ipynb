{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os.path import join\n",
    "from ibm_watson import PersonalityInsightsV3\n",
    "import csv\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import pandas as pd \n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticating with IBM watson service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication via IAM\n",
    "authenticator = IAMAuthenticator('4NzkwQMWUZFocdXsxxDgNFydqc3GT0tS0LR66C1ph4Fa')\n",
    "service = PersonalityInsightsV3(\n",
    "    version='2018-08-01',\n",
    "    authenticator=authenticator)\n",
    "service.set_service_url('https://api.eu-gb.personality-insights.watson.cloud.ibm.com/instances/f44f56f2-44aa-48b1-9801-51481956814c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching big 5 personlaity scores using the IBM watson api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Profile with CSV output #\n",
    "###########################\n",
    "def get_song_persona(filename):\n",
    "    \n",
    "    with open(join(os.getcwd(), f'lyrics/{filename}'), 'r') as profile_json:\n",
    "        response = service.profile(\n",
    "            profile_json.read(),\n",
    "            accept='text/csv',\n",
    "            csv_headers=True).get_result()\n",
    "    \n",
    "    profile = response.content\n",
    "    cr = csv.reader(profile.decode('utf-8').splitlines())\n",
    "    my_list = list(cr)\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating participant's OCEAN score using John & Shrivastava personality scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = genfromtxt('big-5 data.csv', delimiter=',')\n",
    "n, p = my_data.shape\n",
    "ocean_matrix = np.array((n, 5))\n",
    "ocean_matrix = []\n",
    "ocean_matrix.append(my_data[:,5]+my_data[:,10]+my_data[:,15]+my_data[:,20]+my_data[:,25]+my_data[:,30]+(6-my_data[:,35])+my_data[:,40]+(6-my_data[:,41])+my_data[:,44])\n",
    "ocean_matrix.append(my_data[:,3]+(6-my_data[:,8])+my_data[:,13]+(6-my_data[:,18])+(6-my_data[:,23])+my_data[:,28]+my_data[:,33]+my_data[:,38]+(6-my_data[:,43]))\n",
    "ocean_matrix.append(my_data[:,1]+(6-my_data[:,6])+my_data[:,11]+my_data[:,16]+(6-my_data[:,21])+my_data[:,26]+(6-my_data[:,31])+my_data[:,36])\n",
    "ocean_matrix.append(6-my_data[:,2]+my_data[:,7]+(6-my_data[:,12])+my_data[:,17]+my_data[:,22]+(6-my_data[:,27])+my_data[:,32]+(6-my_data[:,37])+my_data[:,42]) \n",
    "ocean_matrix.append(my_data[:,4]+(6-my_data[:,9])+my_data[:,14]+my_data[:,19]+(6-my_data[:,24])+my_data[:,29]+(6-my_data[:,34])+my_data[:,39])\n",
    "ocean_matrix = (np.array(ocean_matrix)/100).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>neuroticism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>24-26 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24-26 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24-26 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>24-26 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>27-30 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>21-23 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>21-23 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>21-23 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>21-23 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>21-23 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age group     Sex  openness  conscientiousness  extraversion  \\\n",
       "0   24-26 years  Female      0.47               0.26          0.21   \n",
       "1   24-26 years    Male      0.43               0.35          0.24   \n",
       "2   24-26 years  Female      0.33               0.24          0.27   \n",
       "3   24-26 years    Male      0.36               0.38          0.30   \n",
       "4   27-30 years    Male      0.42               0.33          0.27   \n",
       "..          ...     ...       ...                ...           ...   \n",
       "57  21-23 years    Male      0.34               0.28          0.25   \n",
       "58  21-23 years    Male      0.25               0.24          0.19   \n",
       "59  21-23 years    Male      0.40               0.38          0.34   \n",
       "60  21-23 years    Male      0.32               0.29          0.23   \n",
       "61  21-23 years    Male      0.36               0.23          0.25   \n",
       "\n",
       "    agreeableness  neuroticism  \n",
       "0            0.34         0.26  \n",
       "1            0.41         0.23  \n",
       "2            0.34         0.28  \n",
       "3            0.41         0.18  \n",
       "4            0.33         0.16  \n",
       "..            ...          ...  \n",
       "57           0.29         0.26  \n",
       "58           0.28         0.29  \n",
       "59           0.42         0.14  \n",
       "60           0.33         0.20  \n",
       "61           0.33         0.26  \n",
       "\n",
       "[62 rows x 7 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generating a pandas dataframe consisting ocean score for each participant\n",
    "ocean_df = pd.DataFrame(data=ocean_matrix, columns=['openness','conscientiousness', 'extraversion', 'agreeableness', 'neuroticism'])\n",
    "demographics_df = pd.read_csv(\"demographics_data.csv\")\n",
    "demographics_df = demographics_df.drop(columns=['id','Which type of music do you prefer listening to?', 'How often do you listen to music with English lyrics?'])\n",
    "final_df_1 = pd.concat([demographics_df, ocean_df], axis=1)\n",
    "final_df_1.to_csv('participants_ocean.csv')\n",
    "final_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_trait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_trait\n",
       "0           0\n",
       "1           0\n",
       "2           3\n",
       "3           3\n",
       "4           0\n",
       "..        ...\n",
       "57          0\n",
       "58          4\n",
       "59          3\n",
       "60          3\n",
       "61          0\n",
       "\n",
       "[62 rows x 1 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traits = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "max_trait = np.argmax(ocean_matrix, axis=1)\n",
    "# max_trait = [traits[i] for i in max_trait]\n",
    "max_trait_df = pd.DataFrame(data=max_trait, columns=['max_trait'])\n",
    "max_trait_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching songs lyrics using AZLIRYCS api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "def get_lyrics(artist,song_title):\n",
    "    # remove all except alphanumeric characters from artist and song_title\n",
    "    artist = re.sub('[^A-Za-z0-9]+', \"\", artist)\n",
    "    song_title = re.sub('[^A-Za-z0-9]+', \"\", song_title)\n",
    "    if artist.startswith(\"the\"):    # remove starting 'the' from artist e.g. the who -> who\n",
    "        artist = artist[3:]\n",
    "    url = \"http://azlyrics.com/lyrics/\"+artist+\"/\"+song_title+\".html\"\n",
    "    \n",
    "    try:\n",
    "        content = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        lyrics = str(soup)\n",
    "        # lyrics lies between up_partition and down_partition\n",
    "        up_partition = '<!-- Usage of azlyrics.com content by any third-party lyrics provider is prohibited by our licensing agreement. Sorry about that. -->'\n",
    "        down_partition = '<!-- MxM banner -->'\n",
    "        lyrics = lyrics.split(up_partition)[1]\n",
    "        lyrics = lyrics.split(down_partition)[0]\n",
    "        lyrics = lyrics.replace('<br/>','').replace('<i>','').replace('</i>','').replace('<div>','').replace('</div>','').strip()\n",
    "        return lyrics\n",
    "    except Exception as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't stay awake for too long\n",
      "Don't go to bed\n",
      "I'll make a cup of coffee for your head\n",
      "It'll get you up and going out of bed\n",
      "\n",
      "Yeah...\n",
      "I don't wanna fall asleep, I don't wanna pass away\n",
      "I been thinking of our future cause I'll never see those days\n",
      "I don't know why this has happened, but I probably deserve it\n",
      "I tried to do my best, but you know that I'm not perfect\n",
      "I been praying for forgiveness, you been praying for my health\n",
      "When I leave this earth, hoping you'll find someone else\n",
      "Cause yeah, we still young there's so much we haven't done\n",
      "Getting married, start a family, watch your husband with his son\n",
      "I wish it could be me, but I won't make it off this bed\n",
      "I hope I go to heaven, so I see you once again\n",
      "My life was kinda short, but I got so many blessings\n",
      "Happy you were mine, it sucks that it's all ending\n",
      "\n",
      "Don't stay awake for too long\n",
      "Don't go to bed\n",
      "I'll make a cup of coffee for your head\n",
      "It'll get you up and going out of bed\n",
      "\n",
      "And I, don't stay awake for too long\n",
      "Don't go to bed\n",
      "I'll make a cup of coffee for your head\n",
      "It'll get you up and going out of bed\n",
      "\n",
      "I'm happy that you're here with me, I'm sorry if I tear up\n",
      "When me and you were younger you would always make me cheer up\n",
      "Taking goofy videos while walking through the park\n",
      "You would jump into my arms every time you heard a bark\n",
      "Cuddle in your sheets, sang me sound asleep\n",
      "And sneak out through your kitchen at exactly 1:03\n",
      "Sundays went to church, on Mondays watched a movie\n",
      "Soon you'll be alone, sorry that you have to lose me\n",
      "\n",
      "Don't stay awake for too long\n",
      "Don't go to bed\n",
      "I'll make a cup of coffee for your head\n",
      "It'll get you up and going out of bed\n",
      "\n",
      "And I, don't stay awake for too long\n",
      "Don't go to bed\n",
      "I'll make a cup of coffee for your head\n",
      "It'll get you up and going out of bed\n",
      "\n",
      "Don't stay awake for too long\n",
      "Don't go to bed\n",
      "I'll make a cup of coffee for your head\n",
      "It'll get you up and going out of bed\n",
      "\n",
      "And I, don't stay awake for too long\n",
      "Don't go to bed\n",
      "I'll make a cup of coffee for your head\n",
      "It'll get you up and going out of bed\n",
      "\n",
      "And I, don't stay awake for too long\n",
      "Don't go to bed\n",
      "I'll make a cup of coffee for your head\n",
      "It'll get you up and going out of bed\n"
     ]
    }
   ],
   "source": [
    "print(get_lyrics(\"powfu\", \"death bed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing song details from the responses filled by the participants\n",
    "def get_song_details(song):\n",
    "    title, artist = song.split(\":\")\n",
    "    title = title.lower().strip()\n",
    "    artist = artist.lower().strip()\n",
    "    return title, artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving participant's song lyrics as txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38, death_bed_by_powfu.txt\n",
      "38, words_by_gregory_alan_isakov.txt\n",
      "38, in_your_eyes_by_the_weeknd.txt\n",
      "38, feel_good_inc_by_gorillaz.txt\n",
      "38, yeah_right_by_joji.txt\n",
      "38, faith_by_the_weeknd.txt\n",
      "38, hardest_to_love_by_the_weeknd.txt\n",
      "38, wish_you_were_sober_by_conan_gray.txt\n",
      "38, hurt_by_johny_cash.txt\n",
      "38, highway_to_hell_by_ac_dc.txt\n",
      "39, lovers_on_the_sun_by_david_guetta.txt\n",
      "39, starving_by_zedd.txt\n",
      "39, blow_your_mind_by_dua_lipa.txt\n",
      "39, one_kiss_by_dua_lipa.txt\n",
      "39, without_me_by_halsey.txt\n",
      "39, right_now_by_nick_jonas.txt\n",
      "39, ignite_by_alan_walker.txt\n",
      "39, on_my_way_by_alan_walker.txt\n",
      "39, dynamite_by_taio_cruz.txt\n",
      "39, lush_life_by_zarra_larson.txt\n",
      "40, let_her_go_by_the_passengers.txt\n",
      "40, ricky_by_denzel_curry.txt\n",
      "40, sad_by_xxxtentacion.txt\n",
      "40, clout_cobain_by_denzel_curry.txt\n",
      "40, wonderwall_by_oasis.txt\n",
      "40, it's_time_by_imagine_dragons.txt\n",
      "41, believer_by_imagine_dragons.txt\n",
      "41, the_nights_by_avicii.txt\n",
      "41, here_comes_the_sun_by_beatles.txt\n",
      "41, astronaut_by_julian_emery.txt\n",
      "41, feel_good_by_daya.txt\n",
      "41, hymes_of_weekend_by_coldplay.txt\n",
      "41, demons_by_imagine_dragons.txt\n",
      "41, stand_by_me_by_alex_d'rosso.txt\n",
      "41, this_feeling_by_the_chainsmokers.txt\n",
      "41, youngblood_by_5_sos.txt\n",
      "42, fallin_by_alicia_keys.txt\n",
      "42, hey_ya_by_outcast.txt\n",
      "42, lose_yourself_by_eminem.txt\n",
      "42, in_da_club_by_50_cent.txt\n",
      "42, poker_face_by_lady_gaga.txt\n",
      "42, beautiful_day_by_u2.txt\n",
      "42, yellow_by_coldplay.txt\n",
      "42, hot_in_herre_by_nelly.txt\n",
      "42, paper_planes_by_m.i.a.txt\n",
      "42, let_me_love_you_by_mario.txt\n",
      "43, dire_straits_by_brothers_in_arms.txt\n",
      "43, pink_floyd_by_shine_on_you_crazy_diamond.txt\n",
      "43, pink_floyd_by_echoes.txt\n",
      "43, pink_floyd_by_cymbaline.txt\n",
      "43, the_doors_by_the_end.txt\n",
      "43, the_doors_by_riders_on_the_storm.txt\n",
      "43, radiohead_by_daydreaming.txt\n",
      "43, made_in_heights_by_death.txt\n",
      "43, made_in_heights_by_panther.txt\n",
      "43, jefferson_airplane_by_today.txt\n",
      "44, believer_by_imagine_dragons.txt\n",
      "44, memories_by_maroon_5.txt\n",
      "44, something_just_like_this_by_coldplay.txt\n",
      "45, tool_by_invincible.txt\n",
      "45, russ_by_nobody_knows.txt\n",
      "45, a_perfect_circle_by_judith.txt\n",
      "45, john_mayer_by_heartbreak_warfare.txt\n",
      "45, the_paper_kites_by_electric_indigo.txt\n",
      "46, stained_glass_by_madison_beer.txt\n",
      "46, like_it_is_by_zara_larrson.txt\n",
      "47, pneuma_by_tool.txt\n",
      "47, burden_by_opeth.txt\n",
      "47, gravity_by_john_mayer.txt\n",
      "47, deliverance_by_opeth.txt\n",
      "47, invincible_by_tool.txt\n",
      "47, russia_on_ice_by_porcupine_tree.txt\n",
      "47, shine_on_you_crazy_diamond_by_pink_floyd.txt\n",
      "47, highest_in_the_room_by_travis_scott.txt\n",
      "47, right_in_two_by_tool.txt\n",
      "47, after_hours_by_the_weeknd.txt\n",
      "48, comethru_by_jeremy_zucker.txt\n",
      "48, do_i_wanna_know_by_arctic_monkeys.txt\n",
      "48, can't_help_falling_in_love_by_elvis_presley.txt\n",
      "48, k._by_cigarettes_after_sex.txt\n",
      "48, cold_mess_by_prateek_kuhad.txt\n",
      "48, the_less_i_know_the_better_by_tame_impala.txt\n",
      "48, trampoline_by_zayn.txt\n",
      "48, lost_start_by_adam_levine.txt\n",
      "48, wish_you_were_here_by_pink_floyd.txt\n",
      "48, let_her_go_by_passenger.txt\n",
      "49, closer_by_the_chainsmokers.txt\n",
      "49, shape_of_you_by_ed_sheeran.txt\n",
      "49, see_you_again_by_wiz_khalifa.txt\n",
      "49, a_thousand_years_by_christina_perri.txt\n",
      "49, numb_by_linkin_park.txt\n",
      "50, we_don't_talk_anymore_by_charlie_puth.txt\n",
      "50, careless_whisperer_by_george_michael.txt\n",
      "50, let_her_go_by_passenger.txt\n",
      "51, cold_blooded_by_zayde_wolf.txt\n",
      "51, no_limits_by_zayde_wolf.txt\n",
      "51, ruleta_by_inna.txt\n",
      "51, taki_taki_by_dj_snake.txt\n",
      "51, wave_walker_by_citizen_way.txt\n",
      "51, new_rules_by_dua_lipa.txt\n",
      "51, i_got_you_by_bebe_rexha.txt\n",
      "51, swalla_by_jason_derulo.txt\n",
      "51, side_to_side_by_ariana_grande.txt\n",
      "51, hymm_for_the_weekend_by_coldplay.txt\n",
      "52, still_corners_by_trip.txt\n",
      "52, still_corners_by_message.txt\n",
      "52, still_corners_by_black_lagoon.txt\n",
      "52, gnash_by_i_hate_u_i_love_u.txt\n",
      "52, zara_larrson_by_never_forget_you.txt\n",
      "52, hailee_stienfled_by_let_me_go.txt\n",
      "52, martin_garrix_by_in_the_name_of_love.txt\n",
      "53, make_you_mine_by_public.txt\n",
      "53, what_if_i_told_you_by_ali_gatie.txt\n",
      "53, death_bed_by_powfu.txt\n",
      "53, adore_you_by_harry_styles.txt\n",
      "53, falling_by_trevor_daniel.txt\n",
      "53, intentions_by_justin_bieber.txt\n",
      "53, eta_by_justin_bieber.txt\n",
      "54, omega_by_periphery.txt\n",
      "54, the_architect_by_haken.txt\n",
      "54, rossetta_stoned_by_tool.txt\n",
      "54, dark_charade_by_rishloo.txt\n",
      "54, kashmir_by_stairway_to_heaven.txt\n",
      "54, april_by_tesseract.txt\n",
      "54, king_by_tesseract.txt\n",
      "54, the_destroyer_by_monuments.txt\n",
      "54, pareidolia_by_haken.txt\n",
      "54, 46&2_by_tool.txt\n",
      "55, cold_by_maroon_5.txt\n",
      "55, rude_by_magic.txt\n",
      "55, adore_you_by_harry_styles.txt\n",
      "55, watermelon_sugar_by_harry_styles.txt\n",
      "55, falling_by_trevor_daniels.txt\n",
      "55, highest_in_the_room_by_travis_scott.txt\n",
      "55, cradles_by_sub-urban.txt\n",
      "56, superhero_by_simon_curtis.txt\n",
      "56, biba_by_marshmello_&_pritam_ft._shirley_setia.txt\n",
      "56, centuries_by_fall_out_boy.txt\n",
      "56, on_&_on_by_cartoon_ft._daniel_levi.txt\n",
      "56, dance_monkey_by_tones_&_i.txt\n",
      "56, hall_of_fame_by_the_script.txt\n",
      "56, whatever_it_takes_by_imagine_dragons.txt\n",
      "56, satisfya_by_imran_khan.txt\n",
      "56, back_to_life_by_hailee_steinfeld.txt\n",
      "56, we_own_it_by_2_chainz_&_wiz_khalifa.txt\n",
      "57, perfect_by_ed_sheeran.txt\n",
      "57, photograph_by_ed_sheeran.txt\n",
      "57, story_of_my_life_by_one_direction.txt\n",
      "57, thousand_years_by_christina_perri.txt\n",
      "57, without_you_by_avicii.txt\n",
      "57, maybe_it's_time_by_bradely_cooper.txt\n",
      "57, sugar_by_maroon_5.txt\n",
      "57, dusk_till_down_by_zayn.txt\n",
      "57, love_me_like_you_do_by_ellie_goulding.txt\n",
      "57, demons_by_imagine_dragons.txt\n",
      "58, dear_god_by_a7x.txt\n",
      "58, closure_by_opeth.txt\n",
      "58, themata_by_karnivool.txt\n",
      "58, new_day_by_karnivool.txt\n",
      "59, audien_by_favorite_sound.txt\n",
      "59, lauren_aquilina_by_you_can_be_king_again.txt\n",
      "59, gnarls_barkley_by_crazy.txt\n",
      "59, snatam_kaur_by_azure_salver.txt\n",
      "59, jim_croce_by_time_in_a_bottle.txt\n",
      "60, memories_by_maroon_5.txt\n",
      "61, the_scientist_by_coldplay.txt\n",
      "61, wake_me_up_by_avicii.txt\n",
      "61, ocean_by_martin_garrix.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "BASE_DIR = \"resources\"\n",
    "\n",
    "num_lyrics = np.zeros(62)\n",
    "\n",
    "with open('songs_data.csv') as csvDataFile:\n",
    "    songs_data = csv.reader(csvDataFile)\n",
    "    \n",
    "    for idx, songs_row in enumerate(songs_data):\n",
    "        for i in range(1, len(songs_row)):\n",
    "            title, artist = get_song_details(songs_row[i])\n",
    "            if(title != \"na\" and artist != \"na\"):\n",
    "                filename = f'{title} by {artist}.txt'\n",
    "                filename = filename.replace(' ','_')\n",
    "                print(f'{idx}, {filename}')\n",
    "                if not os.path.isfile(os.path.join(BASE_DIR, filename)):\n",
    "                    lyrics = get_lyrics(artist, title)\n",
    "                    if lyrics:\n",
    "                        num_lyrics[idx] += 1\n",
    "                        with open(os.path.join(BASE_DIR, filename), 'w') as f:\n",
    "                            f.write(lyrics)\n",
    "                else:\n",
    "                    num_lyrics[idx]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contatinating lyrics in a single file for each individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "BASE_DIR = \"resources\"\n",
    "\n",
    "num_lyrics = np.zeros(62)\n",
    "\n",
    "with open('songs_data.csv') as csvDataFile:\n",
    "    songs_data = csv.reader(csvDataFile)\n",
    "    \n",
    "    for idx, songs_row in enumerate(songs_data):\n",
    "        lf = open(f'lyrics/lyrics_{idx}.txt', 'a+')\n",
    "        \n",
    "        for i in range(1, len(songs_row)):\n",
    "            title, artist = get_song_details(songs_row[i])\n",
    "            filename = f'{title} by {artist}.txt'\n",
    "            filename = filename.replace(' ','_')\n",
    "            lf.write(\"fdcs\")\n",
    "            if os.path.isfile(os.path.join(BASE_DIR, filename)):\n",
    "                with open(os.path.join(BASE_DIR, filename), 'r') as f:\n",
    "                            lf.write(f.read())\n",
    "        lf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating song's lyrics persona using the IBM watson personality insight api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['big5_agreeableness', 'facet_altruism', 'facet_cooperation', 'facet_modesty', 'facet_morality', 'facet_sympathy', 'facet_trust', 'big5_conscientiousness', 'facet_achievement_striving', 'facet_cautiousness', 'facet_dutifulness', 'facet_orderliness', 'facet_self_discipline', 'facet_self_efficacy', 'big5_extraversion', 'facet_activity_level', 'facet_assertiveness', 'facet_cheerfulness', 'facet_excitement_seeking', 'facet_friendliness', 'facet_gregariousness', 'big5_neuroticism', 'facet_anger', 'facet_anxiety', 'facet_depression', 'facet_immoderation', 'facet_self_consciousness', 'facet_vulnerability', 'big5_openness', 'facet_adventurousness', 'facet_artistic_interests', 'facet_emotionality', 'facet_imagination', 'facet_intellect', 'facet_liberalism', 'need_liberty', 'need_ideal', 'need_love', 'need_practicality', 'need_self_expression', 'need_stability', 'need_structure', 'need_challenge', 'need_closeness', 'need_curiosity', 'need_excitement', 'need_harmony', 'value_conservation', 'value_hedonism', 'value_openness_to_change', 'value_self_enhancement', 'value_self_transcendence', 'behavior_sunday', 'behavior_monday', 'behavior_tuesday', 'behavior_wednesday', 'behavior_thursday', 'behavior_friday', 'behavior_saturday', 'behavior_0000', 'behavior_0100', 'behavior_0200', 'behavior_0300', 'behavior_0400', 'behavior_0500', 'behavior_0600', 'behavior_0700', 'behavior_0800', 'behavior_0900', 'behavior_1000', 'behavior_1100', 'behavior_1200', 'behavior_1300', 'behavior_1400', 'behavior_1500', 'behavior_1600', 'behavior_1700', 'behavior_1800', 'behavior_1900', 'behavior_2000', 'behavior_2100', 'behavior_2200', 'behavior_2300', 'word_count', 'processed_language', 'big5_agreeableness_significant', 'facet_altruism_significant', 'facet_cooperation_significant', 'facet_modesty_significant', 'facet_morality_significant', 'facet_sympathy_significant', 'facet_trust_significant', 'big5_conscientiousness_significant', 'facet_achievement_striving_significant', 'facet_cautiousness_significant', 'facet_dutifulness_significant', 'facet_orderliness_significant', 'facet_self_discipline_significant', 'facet_self_efficacy_significant', 'big5_extraversion_significant', 'facet_activity_level_significant', 'facet_assertiveness_significant', 'facet_cheerfulness_significant', 'facet_excitement_seeking_significant', 'facet_friendliness_significant', 'facet_gregariousness_significant', 'big5_neuroticism_significant', 'facet_anger_significant', 'facet_anxiety_significant', 'facet_depression_significant', 'facet_immoderation_significant', 'facet_self_consciousness_significant', 'facet_vulnerability_significant', 'big5_openness_significant', 'facet_adventurousness_significant', 'facet_artistic_interests_significant', 'facet_emotionality_significant', 'facet_imagination_significant', 'facet_intellect_significant', 'facet_liberalism_significant', 'need_liberty_significant', 'need_ideal_significant', 'need_love_significant', 'need_practicality_significant', 'need_self_expression_significant', 'need_stability_significant', 'need_structure_significant', 'need_challenge_significant', 'need_closeness_significant', 'need_curiosity_significant', 'need_excitement_significant', 'need_harmony_significant', 'value_conservation_significant', 'value_hedonism_significant', 'value_openness_to_change_significant', 'value_self_enhancement_significant', 'value_self_transcendence_significant'], ['0.9473702250160589', '0.9739220699354934', '0.7428352961451378', '0.973435125485789', '0.9918664464383896', '0.9585120927079838', '0.2810739160145761', '0.7139296966621944', '0.4715224718533836', '0.4272903385875591', '0.6902102241282861', '0.33365456798782833', '0.4982870583005767', '0.21326979532218393', '0.3733831079970143', '0.48382197046114767', '0.34127842142687637', '0.9188802568312141', '0.6756866995027673', '0.6248000499167075', '0.5121249156337268', '0.9991304424767258', '0.0958060962744331', '0.14669509250363477', '0.5650198315180985', '0.31721784413974446', '0.2792921918629151', '0.5513489468622328', '0.6948040082628626', '0.9654431683003186', '0.9826853984209813', '0.9760990986078751', '0.8331012943353409', '0.9281305392951398', '0.36865578488593004', '0.7972505123045353', '0.45780008312623865', '0.3486367777805771', '0.2587767445395046', '0.9103527903681264', '0.34892472391392004', '0.35448979232874345', '0.40451793449606854', '0.833685451244432', '0.6827996846383968', '0.8367912696503708', '0.8459644094444709', '0.4336207074956699', '0.366458143142389', '0.8301092445848395', '0.08050201701809923', '0.963605428373414', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '736', 'en', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true', 'true']]\n"
     ]
    }
   ],
   "source": [
    "lyrics_persona = []\n",
    "num_participants = 62\n",
    "for i in range(num_participants):\n",
    "    ocean_list = get_song_persona(f'lyrics_{i}.txt')\n",
    "    lyrics_persona.append(ocean_list[1])\n",
    "print(ocean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>big5_openness</th>\n",
       "      <th>big5_conscientiousness</th>\n",
       "      <th>big5_extraversion</th>\n",
       "      <th>big5_agreeableness</th>\n",
       "      <th>big5_neuroticism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>24-26 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.5266808255725408</td>\n",
       "      <td>0.85121544203933</td>\n",
       "      <td>0.431858007717562</td>\n",
       "      <td>0.9164615084904904</td>\n",
       "      <td>0.9715535815763532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24-26 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.2713759187826197</td>\n",
       "      <td>0.639525679652127</td>\n",
       "      <td>0.3919121843067217</td>\n",
       "      <td>0.7723047254411164</td>\n",
       "      <td>0.9451417049359991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24-26 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7769830752728288</td>\n",
       "      <td>0.7896044934588473</td>\n",
       "      <td>0.85869408831672</td>\n",
       "      <td>0.9881644906431961</td>\n",
       "      <td>0.8955405826900422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>24-26 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.18339135298561443</td>\n",
       "      <td>0.11964831669820775</td>\n",
       "      <td>0.5022656167865905</td>\n",
       "      <td>0.24746299495747248</td>\n",
       "      <td>0.8488159757884786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>27-30 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.5852090582382109</td>\n",
       "      <td>0.22693536821345828</td>\n",
       "      <td>0.12429150684211371</td>\n",
       "      <td>0.04882340705400362</td>\n",
       "      <td>0.9398648841362773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>21-23 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.8736189966404528</td>\n",
       "      <td>0.7841996463607356</td>\n",
       "      <td>0.5599234668193237</td>\n",
       "      <td>0.9170240728296242</td>\n",
       "      <td>0.9723481603323543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>21-23 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.47848353663666643</td>\n",
       "      <td>0.2583891094055292</td>\n",
       "      <td>0.019302529897321452</td>\n",
       "      <td>0.6347347770925464</td>\n",
       "      <td>0.7912422162921219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>21-23 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.649814824144349</td>\n",
       "      <td>0.012382092194648364</td>\n",
       "      <td>0.0549703497131358</td>\n",
       "      <td>0.4587200219896725</td>\n",
       "      <td>0.9973258648776249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>21-23 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.2959689735679725</td>\n",
       "      <td>0.8200312902651901</td>\n",
       "      <td>0.1640047152340296</td>\n",
       "      <td>0.8518833561056718</td>\n",
       "      <td>4.678406069508201E-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>21-23 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.6948040082628626</td>\n",
       "      <td>0.7139296966621944</td>\n",
       "      <td>0.3733831079970143</td>\n",
       "      <td>0.9473702250160589</td>\n",
       "      <td>0.9991304424767258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age group     Sex        big5_openness big5_conscientiousness  \\\n",
       "0   24-26 years  Female   0.5266808255725408       0.85121544203933   \n",
       "1   24-26 years    Male   0.2713759187826197      0.639525679652127   \n",
       "2   24-26 years  Female   0.7769830752728288     0.7896044934588473   \n",
       "3   24-26 years    Male  0.18339135298561443    0.11964831669820775   \n",
       "4   27-30 years    Male   0.5852090582382109    0.22693536821345828   \n",
       "..          ...     ...                  ...                    ...   \n",
       "57  21-23 years    Male   0.8736189966404528     0.7841996463607356   \n",
       "58  21-23 years    Male  0.47848353663666643     0.2583891094055292   \n",
       "59  21-23 years    Male    0.649814824144349   0.012382092194648364   \n",
       "60  21-23 years    Male   0.2959689735679725     0.8200312902651901   \n",
       "61  21-23 years    Male   0.6948040082628626     0.7139296966621944   \n",
       "\n",
       "       big5_extraversion   big5_agreeableness      big5_neuroticism  \n",
       "0      0.431858007717562   0.9164615084904904    0.9715535815763532  \n",
       "1     0.3919121843067217   0.7723047254411164    0.9451417049359991  \n",
       "2       0.85869408831672   0.9881644906431961    0.8955405826900422  \n",
       "3     0.5022656167865905  0.24746299495747248    0.8488159757884786  \n",
       "4    0.12429150684211371  0.04882340705400362    0.9398648841362773  \n",
       "..                   ...                  ...                   ...  \n",
       "57    0.5599234668193237   0.9170240728296242    0.9723481603323543  \n",
       "58  0.019302529897321452   0.6347347770925464    0.7912422162921219  \n",
       "59    0.0549703497131358   0.4587200219896725    0.9973258648776249  \n",
       "60    0.1640047152340296   0.8518833561056718  4.678406069508201E-5  \n",
       "61    0.3733831079970143   0.9473702250160589    0.9991304424767258  \n",
       "\n",
       "[62 rows x 7 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generating a pandas dataframe consisting ocean score for each participant's song's lyrics\n",
    "df = pd.DataFrame(lyrics_persona, columns=ocean_list[0]) \n",
    "persona_df = df[['big5_openness', 'big5_conscientiousness', 'big5_extraversion', 'big5_agreeableness', 'big5_neuroticism']]\n",
    "final_df_2 = pd.concat([demographics_df, persona_df], axis=1)\n",
    "final_df_2.to_csv('lyrics_ocean.csv')\n",
    "final_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.concat([persona_df, max_trait_df], axis=1)\n",
    "model_df.to_csv('naive_bayes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
